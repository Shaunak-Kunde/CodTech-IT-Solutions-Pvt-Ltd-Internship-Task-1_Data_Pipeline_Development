# CODTECH Internship â€“ Task 1: Data Pipeline Development  

This project is part of my **CODTECH Virtual Internship** under **Data Science**.  
The goal is to build a **data pipeline** for ETL (Extract, Transform, Load) and perform **exploratory data analysis (EDA)** on the BigBasket dataset.  

---

## ğŸš€ Project Workflow

1. **Data Loading**  
   - Load dataset from Kaggle Link https://www.kaggle.com/code/ridamahmood005/indian-grocery-supermarket-big-basket-eda
   - (`BigBasket Products.csv`) using Pandas.  
   
2. **Preprocessing & Cleaning**  
   - Handle missing values.  
   - Remove duplicates.  
   - Convert data types (e.g., `sale_price`, `discount_pct`).  

3. **Feature Engineering**  
   - Extract useful features like `discount_pct`.  
   - Encode categorical variables (Brand, Category, etc.) for ML compatibility.  

4. **Transformation & Scaling**  
   - Standardize numerical columns using `StandardScaler`.  

5. **Visualization (EDA)**  
   - Distribution of numerical features.  
   - Top 10 brands/products/categories analysis.  
   - Discounts vs Products.  
   - Scatter plot between `sale_price` and `rating`.  
   - Pie charts for category distribution.  

6. **Export Processed Data**  
   - Save cleaned dataset as `BigBasket_Processed.csv`.  
   - For GitHub, only a **sampled dataset** is uploaded due to large size.  

---

## ğŸ“Š Visualizations

- Top 10 categories by product count (pie chart)  
- Top 10 products offering highest discount (%)  
- Scatter plot of Sale Price vs Rating  

---

## ğŸ› ï¸ Tools & Libraries

- **Python 3.10+**  
- **Pandas** â€“ Data handling  
- **NumPy** â€“ Numerical operations  
- **Scikit-learn** â€“ Preprocessing & Scaling  
- **Matplotlib** â€“ Visualization  
- **Seaborn** â€“ Visualization  

---

## ğŸ“‚ Project Structure
Task-1 Data Pipeline Development/
â”‚â”€â”€ BigBasket Products.csv # Original dataset
â”‚â”€â”€ BigBasket_Processed.csv.parquet # Processed dataset (saved locally, sampled for GitHub)
â”‚â”€â”€ bigbasket_pipeline.ipynb # Main Jupyter Notebook
â”‚â”€â”€ requirements.txt # Required Python libraries
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ label_encoders.pkl
â”‚â”€â”€ readme.md # Project documentation
â”‚â”€â”€ scaler.pkl




## ğŸ“Š Summary & Insights

- The **BigBasket dataset** contains multiple categories and brands with varying discounts.  
- **Data Cleaning & Preprocessing** handled missing values, standardized formats, and removed duplicates.  
- **Feature Engineering** created new columns such as:
  - `discount` (absolute difference between market & sale price)  
  - `discount_pct` (percentage discount)  
  - `description_length` (word count of product description)  
- **Transformation** included one-hot encoding for categorical features and scaling of numerical features.  
- **EDA Findings**:
  - Top brands like **Fresho** and **bb Royal** dominate product counts.  
  - Some categories consistently provide higher discounts, giving insights into pricing strategies.  

### âœ… Deliverables
- Clean dataset â†’ `bigbasket_processed.csv`  
- Reusable sklearn pipeline â†’ `bigbasket_pipeline.pkl`  
- Visualizations of brand distribution & discounts  
- Full pipeline automation in this notebook  

## âš ï¸ Note  

- The **processed dataset** is very large (~309MB), so only **sample data** is committed to GitHub.  
- Run the notebook locally with the full dataset for complete results.  

This concludes **Task-1: Data Pipeline Development** for the CodTech Internship ğŸš€

ğŸ‘¨â€ğŸ’» Developed by: **Shaunak Damodar Sinai Kunde**  
